import time
import json
import redis
import pandas as pd
from datetime import datetime
from sqlalchemy.orm import Session

from src.config import config
from src.logger import logger
from src.data_storage import database, crud

class PersistenceService:
    """
    æ•°æ®æŒä¹…åŒ–æœåŠ¡ã€‚
    è´Ÿè´£å®šæœŸå°† Redis ä¸­çš„å®æ—¶è¡Œæƒ…æ•°æ®åŒæ­¥ï¼ˆUpsertï¼‰åˆ° PostgreSQL/TimescaleDBã€‚
    """

    def __init__(self):
        # è¿æ¥ Redis
        try:
            self.redis_client = redis.Redis(
                host=config.REDIS_HOST,
                port=config.REDIS_PORT,
                db=config.REDIS_DB,
                decode_responses=True
            )
            self.redis_client.ping()
            logger.info("æŒä¹…åŒ–æœåŠ¡: Redis è¿æ¥æˆåŠŸã€‚")
        except Exception as e:
            logger.critical(f"æŒä¹…åŒ–æœåŠ¡: Redis è¿æ¥å¤±è´¥: {e}")
            raise

        # æ•°æ®åº“ä¼šè¯å·¥å‚
        self.SessionLocal = database.SessionLocal

    def sync_to_db(self):
        """æ‰§è¡Œä¸€æ¬¡ä» Redis åˆ° DB çš„åŒæ­¥"""
        start_time = time.time()
        
        # 1. è·å– Redis ä¸­æ‰€æœ‰è¡Œæƒ… keys
        keys = self.redis_client.keys('quote:*')
        if not keys:
            logger.info("Redis ä¸­æš‚æ— è¡Œæƒ…æ•°æ®ï¼Œè·³è¿‡åŒæ­¥ã€‚")
            return

        # 2. æ‰¹é‡è·å–æ•°æ®
        values = self.redis_client.mget(keys)
        
        kline_data = []
        for v in values:
            if not v: continue
            try:
                data = json.loads(v)
                # æ•°æ®è½¬æ¢: Redis JSON -> DB Schema
                # æ³¨æ„: Redis é‡Œçš„ time æ˜¯å­—ç¬¦ä¸² "2023-10-27 14:30:00"
                # æˆ‘ä»¬éœ€è¦å°†å…¶è§£æä¸º datetime å¯¹è±¡
                
                # å¤„ç†æ—¥æœŸï¼šå¯¹äºæ—¥çº¿è¡¨ï¼Œå…³é”®æ˜¯æ—¥æœŸéƒ¨åˆ†ã€‚
                # å¦‚æœæˆ‘ä»¬å¸Œæœ›æ¯å¤©åªæœ‰ä¸€æ¡è®°å½•ä¸æ–­æ›´æ–°ï¼Œ
                # é‚£ä¹ˆå…¥åº“çš„æ—¶é—´åº”è¯¥ç»Ÿä¸€ä¸ºå½“å¤©çš„æŸä¸ªæ—¶åˆ»ï¼ˆå¦‚0ç‚¹ï¼‰ï¼Œæˆ–è€…ä¿ç•™æœ€æ–°æ—¶åˆ»ã€‚
                # ä¸ºäº†æ–¹ä¾¿ Upsertï¼ˆæ ¹æ® time, code ä¸»é”®ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿åŒä¸€å¤©çš„æ—¶é—´æˆ³æ˜¯ä¸€è‡´çš„ã€‚
                # è¿™é‡Œæˆ‘ä»¬å–äº¤æ˜“æ—¥æœŸçš„ 00:00:00 ä½œä¸ºä¸»é”®çš„ä¸€éƒ¨åˆ†ã€‚
                trade_time_str = data.get('time')
                if not trade_time_str: continue
                
                trade_dt = pd.to_datetime(trade_time_str)
                trade_date = trade_dt.normalize() # æˆªæ–­åˆ°æ—¥ï¼Œæ—¶é—´ä¸º 00:00:00
                
                item = {
                    'time': trade_date, # å¤åˆä¸»é”®ä¹‹ä¸€
                    'code': data['code'], # å¤åˆä¸»é”®ä¹‹ä¸€
                    'open': float(data['open']),
                    'high': float(data['high']),
                    'low': float(data['low']),
                    'close': float(data['price']), # æœ€æ–°ä»·ä½œä¸ºæ”¶ç›˜ä»·
                    'volume': int(float(data['volume'])),
                    'turnover': float(data['turnover'])
                }
                kline_data.append(item)
            except Exception as e:
                # å¿½ç•¥ä¸ªåˆ«è§£æé”™è¯¯
                continue

        if not kline_data:
            return

        # 3. å†™å…¥æ•°æ®åº“ (Upsert)
        db: Session = self.SessionLocal()
        try:
            crud.bulk_upsert_daily_kline(db, kline_data)
            elapsed = time.time() - start_time
            logger.info(f"æŒä¹…åŒ–å®Œæˆ: åŒæ­¥äº† {len(kline_data)} æ¡è®°å½•ï¼Œè€—æ—¶ {elapsed:.2f}sã€‚")
        except Exception as e:
            logger.error(f"æŒä¹…åŒ–å¤±è´¥: {e}")
        finally:
            db.close()

    def run(self, interval: int = 60):
        """å¯åŠ¨æŒä¹…åŒ–å¾ªç¯"""
        logger.info(f"ğŸš€ å¯åŠ¨æŒä¹…åŒ–æœåŠ¡ (æ¯ {interval} ç§’åŒæ­¥ä¸€æ¬¡)...")
        try:
            while True:
                self.sync_to_db()
                time.sleep(interval)
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ æŒä¹…åŒ–æœåŠ¡å·²åœæ­¢ã€‚")

if __name__ == '__main__':
    service = PersistenceService()
    # æ¯ 10 ç§’åŒæ­¥ä¸€æ¬¡ (æµ‹è¯•ç”¨ï¼Œç”Ÿäº§ç¯å¢ƒå¯è®¾ä¸º 60ç§’)
    service.run(interval=10)

